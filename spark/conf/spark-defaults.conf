#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

spark.deploy.recoveryMode         {{sparkRecoveryMode}}
spark.deploy.zookeeper.url        {{sparkZKUrl}}
spark.deploy.zookeeper.dir        {{sparkZKDir}}

spark.master                      {{sparkMaster}}

# Enable the eventLog, see https://spark.apache.org/docs/latest/monitoring.html#rest-api for the details.
spark.eventLog.enabled            {{sparkEventLogEnabled}}
spark.eventLog.dir                {{sparkEventLogDir}}

spark.history.fs.logDirectory     {{sparkEventLogDir}}

# Refer to http://spark.apache.org/docs/latest/tuning.html,
# The default value is org.apache.spark.serializer.JavaSerializer.
# Kryo is significantly faster and more compact than Java serialization (often as much as 10x),
# but does not support all Serializable types and requires you to register the classes.
spark.serializer                  {{sparkSerializer}}

# fix the oracle "timezone region not found" problem
spark.driver.extraJavaOptions     -Doracle.jdbc.timezoneAsRegion=false -Duser.timezone=UTC
# If RAM is less than 32 GB, set the JVM flag -XX:+UseCompressedOops to make pointers be four bytes instead of eight
spark.executor.extraJavaOptions   {{useCompressedOops}}  -Doracle.jdbc.timezoneAsRegion=false -Duser.timezone=UTC

# Number of cores to use for the driver process, only in cluster mode.
spark.driver.cores                {{sparkDriverCores}}
spark.driver.maxResultSize        {{sparkDriverMaxResultSize}}
spark.driver.memory               {{sparkDriverMemory}}

#Amount of memory to use per executor process (e.g. 2g, 8g).
spark.executor.memory             {{sparkExecutorMemory}}

spark.sql.shuffle.partitions      50
spark.sql.parquet.enable.summary-metadata                       false
spark.hadooop.mapreduce.fileoutputcommitter.algorithm.version   2

